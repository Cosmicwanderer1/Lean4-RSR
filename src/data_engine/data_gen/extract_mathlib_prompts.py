import json
import os
import re
import requests
import zipfile
import io
import glob
from tqdm import tqdm
from typing import List, Dict, Any

# é…ç½®
MATHLIB_URL = "https://github.com/leanprover-community/mathlib4/archive/refs/heads/master.zip"
OUTPUT_DIR = "./data/raw"
OUTPUT_FILE = os.path.join(OUTPUT_DIR, "mathlib_theorems.jsonl")
TEMP_DIR = "./data/temp_mathlib"

class MathlibExtractor:
    def __init__(self):
        # åŒ¹é…å®šç†å£°æ˜Žï¼šæ›´ç²¾ç¡®çš„æ¨¡å¼ï¼Œé¿å…é‡å¤åŒ¹é…
        # ä½¿ç”¨éžè´ªå©ªåŒ¹é…ï¼Œç¡®ä¿åœ¨é‡åˆ°ä¸‹ä¸€ä¸ªå®šä¹‰æ—¶åœæ­¢
        self.theorem_pattern = re.compile(
            r"^(?:(protected|private|noncomputable|scoped)\s+)*(theorem|lemma)\s+(\w+)([\s\S]*?):=\s*(by\s+[\s\S]+?)(?=\n(?:theorem|lemma|def|instance|axiom|\Z))",
            re.MULTILINE
        )
        
        self.import_pattern = re.compile(r"^import\s+([\w\.]+)", re.MULTILINE)
        self.open_pattern = re.compile(r"^open\s+([\w\s]+)", re.MULTILINE)

    def download_mathlib(self) -> str:
        """ä¸‹è½½å¹¶è§£åŽ‹ Mathlib4"""
        if os.path.exists(TEMP_DIR):
            # ç®€å•çš„æ£€æŸ¥ï¼Œç¡®ä¿é‡Œé¢æœ‰æ–‡ä»¶
            if len(os.listdir(TEMP_DIR)) > 0:
                print(f"ðŸ“‚ Found existing Mathlib source at {TEMP_DIR}")
                return TEMP_DIR
            
        print(f"â¬‡ï¸  Downloading Mathlib4 source...")
        try:
            r = requests.get(MATHLIB_URL, stream=True)
            r.raise_for_status()
            z = zipfile.ZipFile(io.BytesIO(r.content))
            print("ðŸ“¦ Extracting zip file...")
            z.extractall("./data")
            
            extracted_folder = os.path.join("./data", z.namelist()[0].split('/')[0])
            if os.path.exists(TEMP_DIR):
                import shutil
                shutil.rmtree(TEMP_DIR)
            os.rename(extracted_folder, TEMP_DIR)
            print(f"âœ… Extracted to {TEMP_DIR}")
            return TEMP_DIR
        except Exception as e:
            print(f"âŒ Download failed: {e}")
            return ""

    def get_module_name(self, file_path: str, source_root: str) -> str:
        """
        æ ¹æ®æ–‡ä»¶è·¯å¾„ç”Ÿæˆ Lean æ¨¡å—åï¼Œç”¨äºŽåšå”¯ä¸€ IDã€‚
        ä¾‹å¦‚: ./data/temp_mathlib/Mathlib/Data/Nat/Basic.lean -> Mathlib.Data.Nat.Basic
        """
        rel_path = os.path.relpath(file_path, source_root)
        # åŽ»æŽ‰ .lean åŽç¼€
        rel_path = os.path.splitext(rel_path)[0]
        # å°†è·¯å¾„åˆ†éš”ç¬¦è½¬æ¢ä¸º .
        return rel_path.replace(os.path.sep, ".")

    def process_file(self, file_path: str, source_root: str) -> List[Dict[str, Any]]:
        """å¤„ç†å•ä¸ª .lean æ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
        except Exception:
            return []

        # 1. æå– Imports & Opens
        imports = []
        open_namespaces = []
        
        # ç®€å•çš„é€è¡Œæ‰«æï¼Œåªæ‰«æå‰ 200 è¡Œä»¥æé«˜æ•ˆçŽ‡ï¼ˆé€šå¸¸ import/open éƒ½åœ¨å¤´éƒ¨ï¼‰
        lines = content.split('\n')
        for line in lines[:200]: 
            line = line.strip()
            if line.startswith('import '):
                match = self.import_pattern.match(line)
                if match: imports.append(match.group(1))
            elif line.startswith('open '):
                line = line.split('--')[0].strip()
                match = self.open_pattern.match(line)
                if match:
                    ns_chunk = match.group(1).split()
                    open_namespaces.extend(ns_chunk)

        # 2. ç”Ÿæˆæ¨¡å—åä½œä¸º ID å‰ç¼€
        module_name = self.get_module_name(file_path, source_root)

        # 3. æå–å®šç†
        extracted = []
        matches = self.theorem_pattern.finditer(content)
        
        for m in matches:
            attrs = m.group(1) or ""
            decl_type = m.group(2)
            name = m.group(3)
            signature = m.group(4).strip()
            proof = m.group(5).strip()

            if "private" in attrs: continue
            if "sorry" in proof: continue

            full_statement = f"{decl_type} {name} {signature}"
            
            # ã€ä¿®å¤ã€‘ä½¿ç”¨ æ¨¡å—å.å®šç†å ä½œä¸ºå”¯ä¸€IDï¼Œè§£å†³æ–‡ä»¶åå†²çªé—®é¢˜
            unique_id = f"{module_name}.{name}"

            extracted.append({
                "id": unique_id,
                "decl_name": name,
                "module": module_name, # è®°å½•æ‰€å±žæ¨¡å—
                "statement": full_statement,
                "imports": imports,
                "open_namespaces": list(set(open_namespaces)),
                "golden_proof": proof,
                "source_file": file_path
            })
            
        return extracted

    def run(self, max_samples=10000):
        source_dir = self.download_mathlib()
        if not source_dir: return

        lean_files = glob.glob(os.path.join(source_dir, "**/*.lean"), recursive=True)
        print(f"ðŸš€ Found {len(lean_files)} Lean files. Processing...")
        
        os.makedirs(OUTPUT_DIR, exist_ok=True)
        
        # ã€æ–­ç‚¹ç»­ä¼ ã€‘è¯»å–å·²æœ‰æ•°æ®ä¸­çš„ID
        seen_ids = set()
        if os.path.exists(OUTPUT_FILE):
            print(f"ðŸ“– Loading existing IDs for deduplication...")
            with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:
                for line in f:
                    try:
                        item = json.loads(line)
                        if 'id' in item:
                            seen_ids.add(item['id'])
                    except:
                        continue
            print(f"âœ… Found {len(seen_ids)} existing theorems.")
        
        count = len(seen_ids)  # ä»Žå·²æœ‰æ•°é‡å¼€å§‹è®¡æ•°
        new_count = 0  # æ–°å¢žçš„å®šç†æ•°é‡
        
        # ä½¿ç”¨è¿½åŠ æ¨¡å¼æ”¯æŒæ–­ç‚¹ç»­ä¼ 
        mode = 'a' if os.path.exists(OUTPUT_FILE) and len(seen_ids) > 0 else 'w'
        with open(OUTPUT_FILE, mode, encoding='utf-8') as f_out:
            for file_path in tqdm(lean_files):
                # ä¼ å…¥ source_dir ä»¥è®¡ç®—ç›¸å¯¹è·¯å¾„
                items = self.process_file(file_path, source_dir)
                
                for item in items:
                    # ã€åŽ»é‡ã€‘æ£€æŸ¥ ID æ˜¯å¦å·²å­˜åœ¨
                    if item['id'] in seen_ids:
                        continue
                        
                    seen_ids.add(item['id'])
                    
                    f_out.write(json.dumps(item, ensure_ascii=False) + "\n")
                    f_out.flush()  # å®žæ—¶åˆ·æ–°ï¼Œé˜²æ­¢æ•°æ®ä¸¢å¤±
                    new_count += 1
                    count += 1
                    
                    if count >= max_samples:
                        break
                
                if count >= max_samples:
                    break
        
        print(f"âœ… Extraction complete!")
        print(f"   ðŸ“Š Total theorems: {count}")
        print(f"   âœ¨ Newly added: {new_count}")
        print(f"   ðŸ’¾ Saved to: {OUTPUT_FILE}")

if __name__ == "__main__":
    extractor = MathlibExtractor()
    extractor.run(max_samples=10000)