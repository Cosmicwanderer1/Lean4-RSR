# lean-proof

è¿™æ˜¯ä½ çš„æœ¬åœ°é¡¹ç›® `lean-proof` çš„ä»“åº“ã€‚ä¸‹é¢æ˜¯å¿«é€Ÿè¯´æ˜ï¼š

å†…å®¹æ¦‚è§ˆï¼š
- `src/`ï¼šé¡¹ç›®æºç 
- `data/`ï¼šåŸå§‹æ•°æ®ï¼ˆåœ¨ `.gitignore` ä¸­å·²æ’é™¤ï¼Œé¿å…ä¸Šä¼ å¤§æ•°æ®ï¼‰
- `models/`ï¼šæ¨¡å‹æƒé‡ï¼ˆå·²æ’é™¤ï¼‰
- `requirements.txt`ï¼šPython ä¾èµ–

æœ¬åœ°å¿«é€Ÿåˆå§‹åŒ–ä¸æ¨é€åˆ° GitHubï¼š
```powershell
cd D:\lean-proof
git init           # è‹¥å°šæœªåˆå§‹åŒ–
git add .          # æ·»åŠ æ–‡ä»¶ï¼ˆæ³¨æ„ .gitignore ä¼šæ’é™¤å¤§æ–‡ä»¶ï¼‰
git commit -m "Initial commit"
# åœ¨ GitHub ä¸Šåˆ›å»º repoï¼Œç„¶åï¼š
git remote add origin https://github.com/<your-username>/<repo>.git
git push -u origin main
```

æ³¨æ„äº‹é¡¹ï¼š
- è¯·åœ¨æ¨é€å‰æ£€æŸ¥ä¸åº”å…¬å¼€çš„æ•æ„Ÿæ–‡ä»¶ï¼ˆAPI keysã€ç§˜é’¥ã€æ¨¡å‹æƒé‡ï¼‰ï¼Œå¿…è¦æ—¶ä½¿ç”¨ Git LFS æˆ–å°†å…¶ä»å†å²ä¸­æ¸…é™¤ã€‚
- å¦‚æœéœ€è¦ï¼Œæˆ‘å¯ä»¥æ›¿ä½ å°è¯•ç”¨ `gh` CLI åœ¨ GitHub ä¸Šåˆ›å»ºä»“åº“å¹¶æ¨é€ï¼ˆéœ€è¦ä½ å·²åœ¨æœ¬æœºç™»å½• `gh`ï¼‰ã€‚
# Lean-RSR: Math Thinker V2 (Pro)

**Lean-RSR** (Reverse Structured Reasoning) æ˜¯ä¸€ä¸ªåŸºäº **Qwen2.5-Math-7B** çš„ç¥ç»ç¬¦å·è‡ªåŠ¨å®šç†è¯æ˜é¡¹ç›®ã€‚æœ¬é¡¹ç›®æ—¨åœ¨é€šè¿‡**é€†å‘ç»“æ„åŒ–æ¨ç†**å’Œ**ä¸“å®¶è¿­ä»£ (Expert Iteration)** æœºåˆ¶ï¼Œæå‡å¤§è¯­è¨€æ¨¡å‹åœ¨ Lean 4 å½¢å¼åŒ–æ•°å­¦è¯æ˜ä¸­çš„èƒ½åŠ›ã€‚

## ğŸš€ æ ¸å¿ƒç†å¿µ

æœ¬é¡¹ç›®æ¨¡æ‹Ÿäººç±»æ•°å­¦å®¶â€œå¤§èƒ†å‡è®¾ï¼Œå°å¿ƒæ±‚è¯â€çš„è®¤çŸ¥è¿‡ç¨‹ï¼ˆSystem 2 æ€ç»´ï¼‰ï¼Œæ ¸å¿ƒåŒ…å«ä¸¤ä¸ªå…³é”®æœºåˆ¶ï¼š

1.  **é€†å‘ç»“æ„åŒ–æ¨ç† (RSR)**ï¼šä¸ä»…ä»…å­¦ä¹ â€œå¦‚ä½•å†™ä»£ç â€ï¼Œæ›´å­¦ä¹ â€œå¦‚ä½•æ€è€ƒâ€ã€‚é€šè¿‡ Teacher Model é€†å‘åˆ†ææ­£ç¡®çš„è¯æ˜ä»£ç ï¼Œæå–å‡º**æ€ç»´é“¾ (Thought Chain)** å’Œ **è¯æ˜éª¨æ¶ (Proof Skeleton)**ï¼Œè®©æ¨¡å‹å­¦ä¼šå…ˆè§„åˆ’åæ‰§è¡Œã€‚
2.  **ä¸“å®¶è¿­ä»£ (Expert Iteration)**ï¼š
    *   **é¢˜æµ·æˆ˜æœ¯ (Massive Generation)**ï¼šæ¨¡å‹å¯¹æ¯é“é¢˜ç”Ÿæˆå¤§é‡å€™é€‰è§£ã€‚
    *   **æ®‹é…·ç­›é€‰ (REPL Filter)**ï¼šåˆ©ç”¨ Lean 4 ç¼–è¯‘å™¨è¿›è¡ŒéªŒè¯ï¼Œåªä¿ç•™ 100% æ­£ç¡®çš„ä»£ç ã€‚
    *   **é€†å‘æ³¨å…¥ (Retrospective Injection)**ï¼šå°†é€šè¿‡ç¼–è¯‘çš„ä»£ç â€œå›ç‚‰é‡é€ â€ï¼Œè¡¥å…¨æ€ç»´è¿‡ç¨‹ï¼Œå½¢æˆé«˜è´¨é‡è®­ç»ƒæ•°æ®ã€‚
    *   **å¾®è°ƒ (Fine-tuning)**ï¼šç”¨è¿™äº›â€œæœ‰æ€ç»´ã€æœ‰éª¨æ¶ã€æœ‰ä»£ç â€çš„æ•°æ®å¼ºåŒ–æ¨¡å‹ã€‚

## ğŸ“‚ é¡¹ç›®ç»“æ„

```
lean-proof/
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml             # å…¨å±€é…ç½®æ–‡ä»¶ (æ¨¡å‹ã€è·¯å¾„ã€è¶…å‚æ•°)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # åŸå§‹æ•°æ®
â”‚   â”‚   â”œâ”€â”€ leandojo_mathlib.jsonl  # Mathlib æå–çš„å®šç†ä¸è¯æ˜
â”‚   â”‚   â””â”€â”€ mathlib_10k_prompts.jsonl # å¾…ç”Ÿæˆçš„ 10k é¢˜ç›®æç¤º
â”‚   â”œâ”€â”€ processed/              # ä¸­é—´å¤„ç†æ•°æ®
â”‚   â”‚   â””â”€â”€ mathlib_10k_solutions.jsonl # æ¨¡å‹ç”Ÿæˆçš„å€™é€‰è§£
â”‚   â”œâ”€â”€ synthetic/              # åˆæˆè®­ç»ƒæ•°æ®
â”‚   â”‚   â””â”€â”€ mathlib_consensus.jsonl # ç»è¿‡ RSR å¢å¼ºçš„é«˜è´¨é‡æ•°æ®
â”‚   â””â”€â”€ temp_mathlib/           # Lean 4 ç¼–è¯‘æ²™ç›’ (Mathlib å‰¯æœ¬)
â”œâ”€â”€ lean_gym/                   # Lean 4 äº¤äº’ç¯å¢ƒ (ç”¨äº REPL éªŒè¯)
â”‚   â”œâ”€â”€ LeanGym/                # Lean æºç 
â”‚   â”œâ”€â”€ lakefile.toml           # Lake æ„å»ºé…ç½®
â”‚   â””â”€â”€ lean-toolchain          # Lean ç‰ˆæœ¬é”å®š
â”œâ”€â”€ models/                     # æ¨¡å‹æƒé‡ç›®å½•
â”‚   â””â”€â”€ math-thinker-7b-pro/    # LoRA Adapter æƒé‡æ–‡ä»¶
â”œâ”€â”€ outputs/                    # è®­ç»ƒè¾“å‡ºç›®å½• (Checkpoints, Logs)
â”œâ”€â”€ src/                        # æ ¸å¿ƒæºä»£ç 
â”‚   â”œâ”€â”€ common/                 # é€šç”¨ç»„ä»¶
â”‚   â”‚   â”œâ”€â”€ prompts.py          # RSR æç¤ºè¯æ¨¡æ¿ (Teacher/Student)
â”‚   â”‚   â”œâ”€â”€ types.py            # æ•°æ®ç±»å‹å®šä¹‰
â”‚   â”‚   â””â”€â”€ untils.py           # è¾…åŠ©å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ data_gen/               # æ•°æ®åˆæˆä¸å¤„ç†
â”‚   â”‚   â”œâ”€â”€ pipeline.py         # æ•°æ®åˆæˆä¸»æµæ°´çº¿
â”‚   â”‚   â”œâ”€â”€ reasoners.py        # æ¨ç†å™¨ (Backward/Forward/Consensus)
â”‚   â”‚   â”œâ”€â”€ run_synthesis.py    # å¯åŠ¨åˆæˆä»»åŠ¡è„šæœ¬
â”‚   â”‚   â””â”€â”€ extract_mathlib_prompts.py # ä» Mathlib æå–é¢˜ç›®
â”‚   â”œâ”€â”€ inference/              # æ¨ç†ä¸ç”Ÿæˆ
â”‚   â”‚   â”œâ”€â”€ generate_solutions.py # æ‰¹é‡é¢˜ç›®ç”Ÿæˆè„šæœ¬
â”‚   â”‚   â”œâ”€â”€ evaluate.py         # è¯„ä¼°è„šæœ¬
â”‚   â”‚   â””â”€â”€ hammer.py           # è¯æ˜æœç´¢å·¥å…·
â”‚   â””â”€â”€ training/               # æ¨¡å‹è®­ç»ƒ
â”‚       â””â”€â”€ train.py            # SFT/LoRA è®­ç»ƒä¸»ç¨‹åº
â”œâ”€â”€ merge_lora.py               # LoRA æƒé‡åˆå¹¶è„šæœ¬
â”œâ”€â”€ run_generation.ps1          # å¿«é€Ÿå¯åŠ¨ç”Ÿæˆçš„ PowerShell è„šæœ¬
â”œâ”€â”€ requirements.txt            # Python ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ STRATEGY.md                 # æŠ€æœ¯è·¯çº¿ä¸æˆ˜ç•¥æ–‡æ¡£
â””â”€â”€ README.md                   # é¡¹ç›®è¯´æ˜æ–‡æ¡£
```

## ğŸ› ï¸ ç¯å¢ƒå®‰è£…

1.  **Python ç¯å¢ƒ**:
    ```bash
    pip install -r requirements.txt
    ```
    *æ³¨æ„ï¼šWindows ç”¨æˆ·å®‰è£… `bitsandbytes` å¯èƒ½éœ€è¦ç‰¹å®šç‰ˆæœ¬æˆ–é¢„ç¼–è¯‘åŒ…ã€‚*

2.  **Lean 4 ç¯å¢ƒ**:
    ç¡®ä¿å·²å®‰è£… Lean 4 å’Œ Lakeï¼Œå¹¶åˆå§‹åŒ– `data/temp_mathlib` ç›®å½•ä»¥ä¾¿è¿›è¡Œç¼–è¯‘éªŒè¯ã€‚

## ğŸš¦ ä½¿ç”¨æŒ‡å—

### æ•°æ®ç”Ÿæˆæµæ°´çº¿ (Data Engine Pipeline)

æœ¬é¡¹ç›®é‡‡ç”¨**ä¸‰é˜¶æ®µæ•°æ®ç”Ÿæˆæµæ°´çº¿**ï¼ˆè¯¦è§ `ARCHITECTURE.md`ï¼‰ï¼š

#### æ–¹å¼ä¸€ï¼šå®Œæ•´æµæ°´çº¿ï¼ˆæ¨èï¼‰
```powershell
# ä¸€é”®è¿è¡Œ Forward â†’ Backward â†’ Consensus
python run_full_pipeline.py --max-samples 50
```

#### æ–¹å¼äºŒï¼šåˆ†é˜¶æ®µè¿è¡Œ
```powershell
# Phase 1: æ­£å‘è§„åˆ’ï¼ˆæ¢ç´¢ç­–ç•¥ï¼‰
python run_phase1_pipeline.py --max-samples 50

# Phase 2: é€†å‘åˆ†æï¼ˆæå–éª¨æ¶ï¼‰
python run_phase2_pipeline.py --max-samples 50

# Phase 3: å…±è¯†è£å†³ï¼ˆèåˆç»“æœï¼‰
python run_phase3_pipeline.py --max-samples 50
```

**è¾“å‡º**:
- Phase 1: `data/step1_planning/mathlib_plans.jsonl`
- Phase 2: `data/step2_backward/backward_analysis.jsonl`
- Phase 3: `data/step3_consensus/final_training_data.jsonl` â­ ç”¨äºè®­ç»ƒ

---

### 1. å¤§è§„æ¨¡ç”Ÿæˆ (Generation - å·²å¼ƒç”¨)
**æ³¨æ„**: æ­¤è„šæœ¬ç”¨äºç›´æ¥ç”Ÿæˆè¯æ˜ï¼Œç°å·²è¢«ä¸‰é˜¶æ®µæµæ°´çº¿å–ä»£ã€‚
```powershell
# ä½¿ç”¨ PowerShell è„šæœ¬å¿«é€Ÿå¯åŠ¨
.\run_generation.ps1

# æˆ–è€…ç›´æ¥è¿è¡Œ Python è„šæœ¬
python src/inference/generate_solutions.py
```
*   é…ç½®ï¼šé»˜è®¤æ¯é¢˜ç”Ÿæˆ 32 ä¸ªæ ·æœ¬ (Temperature 0.7)ã€‚
*   è¾“å‡ºï¼š`data/processed/mathlib_10k_solutions.jsonl`

---

### 2. è®­ç»ƒ (Training)
ä½¿ç”¨åˆæˆçš„é«˜è´¨é‡æ•°æ®å¯¹æ¨¡å‹è¿›è¡Œ LoRA å¾®è°ƒã€‚
```bash
python src/training/train.py
```
*   é…ç½®ï¼šå¯åœ¨ `configs/config.yaml` ä¸­è°ƒæ•´ Batch Size, Learning Rate, LoRA Rank ç­‰ã€‚
*   ç‰¹æ€§ï¼šæ”¯æŒ 4-bit QLoRAï¼Œé’ˆå¯¹ RTX 4090 ä¼˜åŒ– (Flash Attention 2 / SDPA)ã€‚

### 3. æ¨¡å‹åˆå¹¶ (Merge)
å°†è®­ç»ƒå¥½çš„ LoRA æƒé‡åˆå¹¶å› Base Modelï¼Œä»¥ä¾¿éƒ¨ç½²æˆ–è¿›è¡Œä¸‹ä¸€è½®è¿­ä»£ã€‚
```bash
python merge_lora.py
```

## ğŸ—ºï¸ è·¯çº¿å›¾ (Roadmap)

æ ¹æ® `STRATEGY.md`ï¼Œæœ¬é¡¹ç›®çš„æ¼”è¿›è®¡åˆ’å¦‚ä¸‹ï¼š

*   **Phase 1: é—­ç¯éªŒè¯ä¸æ•°æ®å¼•æ“** (å½“å‰é˜¶æ®µ)
    *   [x] å®ç°åŸºç¡€çš„ä¸“å®¶è¿­ä»£ (ExIt) æµç¨‹ã€‚
    *   [ ] æ·±åº¦é›†æˆ `lean_gym` åˆ°æ•°æ®ç”Ÿæˆè„šæœ¬ã€‚
    *   [ ] åˆ©ç”¨ Teacher Model å¯¹ Mathlib ä»£ç è¿›è¡Œâ€œå»é«˜å°”å¤«åŒ–â€ã€‚

*   **Phase 2: æ£€ç´¢å¢å¼ºä¸çŠ¶æ€äº¤äº’**
    *   [ ] éƒ¨ç½²å‘é‡æ•°æ®åº“ï¼Œç´¢å¼• Mathlibã€‚
    *   [ ] æ”¹é€ æ¨ç† Promptï¼ŒåŠ å…¥ RAG æ£€ç´¢ä¿¡æ¯ã€‚

*   **Phase 3: æœç´¢ç®—æ³•ä¸å…±è¯†å‡çº§**
    *   [ ] å®ç°åŸºäºæ ‘æœç´¢çš„æ¨ç†å¼•æ“ (R-GTS)ã€‚
    *   [ ] å°†â€œå…±è¯†è£å†³â€è®­ç»ƒä¸ºè½»é‡çº§ä»·å€¼ç½‘ç»œã€‚

## ğŸ“Š æŠ€æœ¯æŒ‡æ ‡

*   **Base Model**: Qwen/Qwen2.5-Math-7B-Instruct
*   **Training Strategy**: Rejection Sampling Fine-Tuning (RFT) + RSR
*   **Hardware**: Optimized for Consumer GPUs (RTX 3090/4090)

## ğŸ“ å¼•ç”¨ä¸è‡´è°¢

æœ¬é¡¹ç›®æ·±å— DeepSeek-Prover, AlphaProof åŠ LeanDojo ç­‰å‰æ²¿å·¥ä½œçš„å¯å‘ã€‚


